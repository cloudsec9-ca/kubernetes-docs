URL reference: https://dev.to/jamallmahmoudi/kubernetes-certificate-expiration-x509-1g7d
DateReviewed: 2024-08-01
Description: Seems it's important to understand Cert management for Kubernetes. The motivation they use isn't too strong, just talking about lapsed renewal instead of talking about why you want TLS. We get a laundry list of what certificates are in general, and then what Kubernetes does with them. We then move to the meat of this article -- checking cert validity and expiration. They show CLI commands to display various bits to display the expiry from either openssl or kubeadm. They wisely advise backing the certs up, and then walk through the commands to renew the certs. They also advise to restart the pods and also to do some clean up. Overall a good base, but would have been better with a bit more flow and organisation.
BottomLine: Decent piece on the renewal of TLS certs in Kubernetes
==
URL reference: https://github.com/digitalis-io/vals-operator
DateReviewed: 2024-08-02
Description: This is a repo to keep secrets in sync between an external secret store and Kubernetes secrets so they can be used in various pods. The repo has a video walkthrough, install instructions and examples of how to integrate with various stores, like AWS Secrets Manager and HashiCorp Vault for example. They even mention how to do password rotation as an advanced topic.
BottomLine: Interesting repo allowing you to integrate external secrets seemlessly into Kubernetes
==
URL reference: https://medium.com/@martinko.komorny/grafana-agent-alloy-loki-minio-grafana-in-kubernetes-4fe4894b1341
DateReviewed: 2024-08-03
Description: This article goes through setting up a logging service in Kubernetes. After the motivation, we start with a diagram -- I hope that's a good sign. We also start with great advice - ensure proper logging of your apps. They then talk a bit about the Java logging piece they use and ints config. They include a sample XML file for their logger config. We now move on to some microservices that are logging in JSON format. The LGTM stack uses Minio for storage, which is an S3 like on-prem object store. They give the YAML to get this running. We now move onto managing the stored log files with Loki. There are a few options, and they went with a simple scalable install for Loki. This creates three services - writer, reader and backend. Loki uses labels to write and then read the logs, which it uses for indexing and faster searches. We then get a Helm chart to do the Loki install and setup. Once this is done, we turn to feeding the data into the logging system. In the past we might have used Grafana agent, but this has now been replaced with Alloy which our author opts for. Again we deploy Alloy from a Helm chart. Last but not least, we want to see our logs, so we do the visualizaion through Grafana and deploy this with another Helm chart. It's a good walkthrough.
BottomLine: Walk through setting up logging for Kubernetes
==
URL reference: https://rakowskiii.medium.com/charting-the-waters-exploring-kubernetes-basics-through-a-security-researchers-lens-3c7964ea8d15
DateReviewed: 2024-08-04
Description: So this article will be looking into Kubernetes basics from a security perspective. We start with the usual "what is Kubernetes", and then we move onto the core concepts. (There is a weird unhelpful diagram here). They go through namespaces, pods, nodes, services, and deployments. Each gets a solid paragraph explaining what it is. Now we dive into the architecture, and cover the control plane and node concepts, with sub-concepts covered for each higher level area. We finally get to security, and here we cover network policies, pod security policies, secrets management, and audits. Each has a paragraph on it. So, it's a decent high level overview for someone who has never seen K8s before.
BottomLine: Good high level intro to Kubernetes security for a beginner
==
URL reference: https://securityboulevard.com/2024/07/why-kubernetes-doesnt-manage-users/
DateReviewed: 2024-08-05
Description: This article tackles the question of why Kubernetes doesn't manage users. First, they explain how authentication and authorization happen in Kubernetes - where TLS is used with Certs to figure out what identity should be used and if it is valid, and then RBAC to figure out what an identity should have access to. They point out that this is challenging for larger deployments, so K8s has ability to offload these parts to third party AA providers. They then go through some of the reasons orgs may want to do their own auth, which includes a diverse set of use cases and different security considerations. Next up, we look at ways to hook external connectors for auth up, and these include OIDC, LDAP and Webhooks with custom auth plugins. They then go through each option in turn, with a large secton on how they work, how to config, test, and then configure RBAC to work with them. They tie this up with a motivator on using RBAC properly and suggestions on which 3rd pary auth to use when. Oveall a solid piece.
BottomLine: Good primer and setup walkthrough of user auth on Kubernetes
==
URL reference: https://cloudbelievers.blogspot.com/2024/07/securing-your-kubernetes-kingdom-basics.html
DateReviewed: 2024-08-06
Description: This is supposed to be an article about AKS, but the formatting is bad. On Firefox, the first paragraph is just one long line, which is not great. I'm not usually that worried about this stuff, but makes reading challenging. This is focused on Azure, but it's pretty thin. We get good headings, including network security, identity and access management, container security, secrets management and finally monitoring and logging. Under each heading, we get 2 or usually 3 bullet points on what to do. They then have a section on Best practices which is another 5 bullet points, and finishes with 3 additional consideration points. My honest take is that someone had an idea but not time to write a full article, so did the minimum. The points aren't bad, but everything is super terse and feels like a person new to Azure/AKS would be intimidated by this approach.
BottomLine: Super lean approach to Azure Kubernetes security
==
URL reference: https://medium.com/@kamransharief7/crafting-optimal-container-images-best-practices-for-security-and-efficiency-c7ff89c7d424
DateReviewed: 2024-08-07
Description: This article aims to create optimal container images, which help with both performance and security. We jump right into an issue - that of reaching the DockerHub limit. They suggest alternatives like an alternate Registry, or if your infra is in the cloud, you can use the one for your cloud provider - eg ECR for AWS. Next up is using build contexts, and only copying the directories you need for deployment to the final image. Along these lines, they have suggestions for multi-arch builds and image caching, before explaing the usage of golden image creation. Each of these get about a paragraph explaining what they are and why you may want to use them. Now they start on optimizing, and we start with multi-stage builds - creating one image for the build part, and then just taking what is needed for the run to copy over. They also talk about minimizing layers and starting with lightweight images, again to reduce size and attack surface. We now switch to securing our container, which includes thinking about how environment variables are used. They go through doing a vulnerability scan, and also not using the root user if possible. They also recommend avoiding image:latest, which refers not to a specific version, but just the last one currently tagged.
BottomLine: Excellent coverage of optimizing and securing images for Docker and Kubernetes
==
URL reference: https://thenewstack.io/can-cilium-be-a-control-plane-beyond-kubernetes/
DateReviewed: 2024-08-08
Description: This article is based on an interview of one of the Cilium leads, and talks about where Cilium is going in the future. First, we get a background of the current landscape, and how eBPF has helped and been integrated into Kubernetes with Tetragon. The article shifts a bit to highlight AI and what the demands are there. The arguement made is that AI is better automation, allowing you to mitigate threats and issues in a more proactive way. The role they see for Cilium in this is one of universal data plane, but they don't say what this looks like. There is a bit of handwaving about software-defined networking, so perhaps at that level? (Side note - Cilium is powered by eBPF, and the article doesn't clarify that). They do mention that it's a question of whether eBPF can handle both layer 4 and layer 7 traffic that is needed. After this warm up, there are acutally quotes from the interviews with Youtube snips. In this part, they talk about what cloud native security might look like, issues with service mesh, how NSX fits into the picture, and ends with a little bit on the Cisco acquisition of Isovalent.
BottomLine: Interesting talk on the role eBPF/Cilium plays in and outside of Kubernetes
==
URL reference: https://traefik.io/glossary/understanding-multi-cluster-kubernetes/
DateReviewed: 2024-08-09
Description: This article looks into multi-cluster Kubernetes. We dive in quickly and are told that any config where we have more than one cluser fits - multiple on the same hosts, different hosts in the same DC, or multiple clouds. We then do a tour of a normal cluster and the control/data/worker planes, along with a diagram. Apparently the extra part in the multi-cluster is a global load balancer outside of the traditional K8s infra with another diagram. But they go on to explain, this is just one of a number of multi-clust configs. They break down both segmented vs repication and K8s centric vs network centric, with a couple paragraphs fleshing things out. They then have a longer section covering the benefits, with bits dedicated to flexibility, availability, scalability and resource utilization, workload isolation and security and compliance, with a few paragraphs for each. They also detail the drawbacks, including complexity, config, security, deployment and cost. Overall, a good treatment of the topic.
BottomLine: Good overview of what multi-cluster Kubernetes is and the benefits and drawbacks
==
URL reference: https://blog.davidv.dev/posts/first-contact-with-k8s/
DateReviewed: 2024-08-10
Description: This is a blog on a skeptics first experience with Kubernetes. We start with a section on the author and his approach, and that this is his experience and opinion. He takes a practical approach, and starts from first principles, doing a brief description of what K8s is in the abstract before moving on to define the various resources that are used in K8s. He even illustrates with a diagram. He has a great explaination of controllers - they are "control loops" that use sensors to perform actions on workloads. He has a few examples, like a sensor looking for latency, and if it grows beyond a certain point spinning up more pods. He then talks about how a service works, and the various mechanics to have it run seemlessly. He pegs it as a network resource, where you get a stable endpoint (IP/port) which is then mapped to pods which support the underlying app. They even go through a traffic flow diagram. Next we move on to what he calls workload management - they show an imperitive invocation, and then explain a replica set and how this is a declarative invocation. The last K8s thing he tackles is storage, explaining ephemeral storage along with durable storage through Persistent volumes. He then documents some open questions and things he hasn't explored, which is neat. He also includes a small rant against something he sees as an issue in various config files. Overall, a great read and recommended.
BottomLine: Recommended piece about someone taking their first run at Kubernetes
==
URL reference: https://securitylabs.datadoghq.com/articles/kubernetes-security-fundamentals-part-4/
DateReviewed: 2024-08-11
Description: This article is part of a series, and this installment focuses on authorization, or what a verified user can do. We start with a diagram, which is always a good sign. They note upfront that there are flexible authorization modules, which allow multiple ways to do this auth. These can be chained together, and modules can do an explicit approve or deny, or alternatively respond "no opinion", which drops through to the next member of the chain. If all chain members respond "no opinion", the request is implicitly denied. They note that since auth is split up, there is no way to get all permissions a user has easily, and all of the configs have to be audited one by one. They note there is a special group, system:masters, which is like root and doesn't check auth modules, but they also note ordinary users should never be placed in this group for that reason. They talk about some special modes, including Node Authorizer, which is intended to restrict priv escalation. Normally kubelet has access to all secrets, to be able to provide them to requesting pods, but a compromise can allow an attacker access to the kubelet; the idea here is to restrict this to kubelets running on nodes. They also mention AlwaysAllow and AlwaysDeny, along with ABAC, an attribute-based control run from static JSON files on nodes, which is rarely used because of the lack of flexibility. Next is RBAC, which they have a diagram for and go into decent detail about. We end this section with a dive into Webhook, which allows a call to an external provider that returns a response. We then talk about other components, like Kubelet and the Scheduler and Controller manager and how they are controlled. While this is a shorter piece, it's clear and well delivered, and a recommend.
BottomLine: Recommended piece on Kubernetes security fundamentals
==
URL reference: https://itnext.io/full-guide-how-to-easily-publish-helm-charts-on-github-with-github-pages-0a24507523ae
DateReviewed: 2024-08-12
Description: This article is the all in one guide to publishing Helm charts in GitHub. It starts with a diagram, which I like, and also a heads up -- that some things can be done better using OCI, and include a reference. We dive in by starting at the beginning, and installing Helm. We then use the CLI to create a chart, and tweak the config files (and they include a link to a repo to help with this). They do an error check, and then check out a file to create docs. We're taken through a couple YAML configs with explainations. We now turn to Git, and we issue a CLI command to create a branch, and then we need to complete the Helm bits -- they give two options, one copying a file and the other using Helm to "package" the chart and generate the file. Now we need to deploy the Chart to get something to happen. To do this, we commit/push our Helm Chart and then have to do a bit of setup on the GitHub side (with a video walkthrough). Once set up, they bump the version number, push it and observe that the workflow runs. They then run through using or installing/templating your chart, and finally how to publish your Helm chart on artifacthub.io. Pretty good walkthrough.
BottomLine: Walkthrough of using Helm charts to create GitHub workflows
==
URL reference: https://dev.to/thenjdevopsguy/implementing-kubernetes-pod-security-standards-4aco
DateReviewed: 2024-08-13
Description: In an entirely new development, Kubernetes is good and bad security is caused by misconfigs. We waste no time and dive right into things with Pod Security Standards - there are three enforcement levels. First up is privleged, which allows the most actions and is the least restrictive. Restricted is the least permissive, and can sometimes cause issues with apps running in it. It's the goal, but not always where you can run every app. The middle ground is baseline, which is more permissive but does try to mitigate priv escalations. We are then introduced to the Pod security admission controller, which is how Kubernetes enforces security. We pivot back to PSS to talk about levels -- namely the Cluster and Namespace levels, which impacts how and where they are available and what they do. Cluster level allows you to enforce security configs cluster wide, while also allowing you to include exceptions. The drawback is that this won't be avialable on most managed K8s providers. On the pod level, we go through an actual config by setting up a namespace and applying the PSS with YAML and CLI bits. They do note a few namespaces - default, kube-public, kube-system - are at the privileged level by default. Overall a decent walkthrough.
BottomLine: Intro and short walkthrough of Pod Security Standards for Kubernetes
==
URL reference: https://blog.devops.dev/31-kubernetes-overview-basic-components-kubectl-mini-kube-commands-used-in-pods-in-kubernetes-07b5a7ffdb70
DateReviewed: 2024-08-13
Description: This isn't an article as much as a primer on some of the basic commands for a Kubernetes cluster. We start with a few sentences on Minikube and Kubectl so you know what we're talking about. Next up is Commands, so they start with a run command to start a pod and a get pods to check that it's running. We look at a variation of the previous commands to give a bit more info, and then a describe pods to give us lots of details. They include a snip of the output so we know what the output should look like. We are then taken through the delete command to clean up a pod no longer needed, with a bit of explaination. We then are shown how to use YAML to create a pod. They throw in some links for further exploration.
BottomLine: Very basic intro with Minikube and the Kubernetes CLI
==
URL reference: https://medium.com/@haroldfinch01/docker-swarm-kubernetes-mesos-coreos-fleet-a-comparative-guide-646afd10a6be
DateReviewed: 2024-08-14
Description: Apparently this container stuff is getting into the standards track, so with no clear leader this author figured doing a comparison was a good idea. We dive right in with Docker Swarm, and we get an intro, some key features, and a few one-line use cases. For Swarm, the big selling point is tight integration with Docker, making it easy to use. Next up is Kubernetes, which they do mention is the industry standard, and it gets the same key features and one liner use cases. They position K8s for large complex workloads. Next up is Apache Mesos, whose main draw is abstraction of all compute - CPU, memory, storage - enabling fault-tolerant systems. It echos the key features and use cases. Last up is CoreOS Fleet, a way to manage a cluster that is already running a CoreOS on the members, and it again gets the key features and use cases roundup. They don't come out with a winner, but rather say it depends on your team and needs, which is fair. It's a good intro to alternatives, which are always good to consider.
BottomLine: Good quick comparison of Kubernetes and a number of other orchestrators for clusters
==
URL reference: https://thenewstack.io/crowdstrike-a-wake-up-call-for-ebpf-based-endpoint-security/
DateReviewed: 2024-08-15
Description: Recently there was a CrowdStrike issue which caused issues with millions of computers - our article ponders if there was a way to prevent that. We start with bullet points and then a recap of the outage, where a faulty sensor file caused a crash. They claim that the issues was due to "dated architecture", and that managing kernel drivers can be difficult, as they have ultimate access. They go on to question the viability of having such elevated access granted to things like CrowdStrike's app. They also express doubt about SaaS solutions. They advance eBPF as a way to manage this risk, as it is sandboxed in its kernel access. Another tact would be something like a phased rollout. They go on to argue that concentration is bad, and that since it was widely deployed, this shows the system was fragile. They argue that diversity is helpful. We now circle back to eBPF, with a highlight to the benefits without really touching on how eBPF solves this issue. They then handwave a bit at stopping attacks in real time with eBPF. Okay, now for my take -- wow. I feel this piece says to use eBPF to "solve" the problem, but it never says HOW it solves this problem. Don't get me wrong -- I think eBPF can be a solid tool in the security toolbox. But CrowdStrike is a threat intel and attack mitigation tool, which uses signatures and instruments to locate threats. eBPF can do SOME of that, but not all, and not like CrowdStrike -- they are mostly complimentary tools. If the piece said "if you had eBPF in there and configured right, you could have stopped this update" .. okay, that may be valuable. But that doesn't seem to be the arguement here. So, it's an interesting read but be skeptical.
BottomLine: Security piece that advocates using eBPF in light of CrowdStrike issue but does so disjointedly
==
URL reference: https://signoz.io/blog/loki-vs-elasticsearch/
DateReviewed: 2024-08-16
Description: This is a comparision of two log analytics tools - Elasticsearch/ELK stack and Loki with Grafana. We start with a paragraph on why logging is improtant and why we want to analyze logs with tools. Next up is a toe dip - Elasticsearch uses a lot of resources to do a deep index while Loki only indexes labels associated with log lines, making things much faster. Then we get into what each tool is in more detail, starting with Loki and then going on to Elasticsearch. It explains how each of them work, and a bit of the benefits and challenges. We also get a chart with the comparison features. Now we go through major features and how each tool deals with them. They go through storage, indexing, query language, log ingestion and user interface. Each section gets at least a paragraph, with some getting much more, and the UIs getting screenshots. Oddly, as they are winding down they pitch SigNoz as an alternative, which is by the hosters of th page. Feels like they paid someone to compare the first two, then stapled this on as a bit of a pitch.
BottomLine: Decent comparison of Loki and Elasticsearch as log analysis platforms for Kubernetes
==

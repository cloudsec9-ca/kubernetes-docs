URL reference: https://medium.com/@josielol/unleashing-the-t-rex-how-containers-sometimes-fail-to-contain-1710b6cc7990
DateReviewed: 2024-11-01
Description: Our article here is going to touch on how containers sometimes fail to contain - and they start with an analogy to Jurrasic Park, and how the dinos were not contained. We dive in starting with container basics, going though how it's a single bundle running on an OS, which is mostly isolated. They point out that at a low level, a container is just a child on the host system. We get a neat diagram illustrating containers/namespaces and the Linux features that help out. The container runtime are the gates, allowing containers to start, do things, and stop. But they say, gates sometimes fail. We get another diagram, with arrows and a label of container escapes, so let's see what we're going to delve into. They talke about permission issues with mounts, allowing unintended file access; or a buffer overflow, allowing access to shared memory. Misconfigs can even allow CLI commands on the host from the container, and lastly, priv escalation that results in root access, allowing the attacker carte blanche. Next up they are going to do a demo with eBPF. They say that clever code can get around the verifier and JIT compiler, allowing execution of unsafe bytecode. They go into a bit of detail on how the verifier works, ensuring there are no unreachable instructions and simulating each control branch. They point to a few actual instances of CVEs involving the verifier, and are going to focus on a recent one. The walkthrough is quite simple - we build a user container, include the nasty code in the image, then run the binary and are root when done. Pretty cool. They go into mitigations with supply chains and SBOMs, but basically you have to be vigilant. Excellent article.
BottomLine: Awesome article showing a straightforward container escape in Kubernetes
==
URL reference: https://achievers.engineering/load-testing-kubernetes-resolving-bottlenecks-and-improving-performance-part-2-c4f08102f105
DateReviewed: 2024-11-01
Description: This article is a followup on a previous case where they did some performance tuning. They take that as a baseline and attempt to get even more throughput here. We start by looking at metrics like throughput, errors, latency and scalability. They assign goals, like doubling the baseline throughput, as where they want to go. They mention that as Kubernetes scales the cluster, that current strategy doesn't take full advantage, as already connected clients stay with the same pods, impeding proper load balancing. They show this in a graph. They say using Istio solves this, as it has proxies to help loadshare better, and so they move to this. They show the YAML needed, and an after graph, showing a much more even usage among the clients. They talk a bit about errors and latency, and it's important to note these are config only changes -- none of this needs any code change so far. Next they show how by doing tiny tweaks you can get some exta performance out of the system. They go through a few more esoteric tweaks, before circling back and noting they had achived all of the goals they had put out. Interesing but highly technical piece.
BottomLine: Low level performance tweaks to get more out of your Kubernets cluster
==
URL reference: https://aws.plainenglish.io/kubernetes-networking-in-the-simplest-way-d84e3b7ed940
DateReviewed: 2024-11-02
Description: This article aims to introduce Kubernetes networking in a simple way. We start with a diagram, so that is good. We dive in basically right away, covering basics, like each pod getting an IP and not needing to link or map things internally for K8s. They also explain that each pod can talk to any other pod without NAT, and programs on a node can talk to all pods on that node by default. Next we cover four concerns - now containers in a pod talk, how cluster networking allows comms between pods; how services allow apps to be reached from outside the cluster, and that services can be used inside the cluster. To finish up, we get some YAML files and CLI commands to demonstrate. Overall, it's decent but seems not well formed and flowing, so I'd say an okay toe dip.
BottomLine: Ok intro to Kubernetes networking and related concepts
==
URL reference: https://www.cncf.io/blog/2024/10/17/keep-up-with-cloud-native-and-kubernetes-security-with-the-updated-cks-certification/
DateReviewed: 2024-11-02
Description: This article talks about updates to the CNCF exam. First, they start by highlighting the growth of the Kubernetes community and CNCF in the past few years, including the number of people certified. They then explain that as things evolve and change, so must the skills that people have and also the exams. The exam was updated on October 15th, and while things like cluster stup and hardening will remain, some things will be phased out while others will be added, and some of the weights may change. My take -- I wish they'd talked a bit more about the broad areas of change, like what new topics would be included and what will be phased out.
BottomLine: News about changes to the CNCF certification exam but no details
==
URL reference: https://medium.com/@simardeep.oberoi/cilium-advanced-network-policies-and-observability-in-kubernetes-fbb4fdd747ba
DateReviewed: 2024-11-03
Description: We start with Kubernets being great, but it only able to manage layer 3 and 4 traffic - implying we're missing some observability. To our rescue comes Cilium, which they point out can do Layer 7 traffic control and all kinds of other bells and whistles including observability. They also point out that while K8s uses IP based traffic models, Cilium uses pod labels to ensure even if IPs change due to K8s dynamic nature, policies are applied correctly. We then do a bit of CLI and YAML exploring, to get some hands on. Further, they point out we can filter not just on destination, but on things like the URL path and request method, giving much finer grained control. We do some more hands on, and then talk a bit about high-performance considerations. Overall a good article.
BottomLine: Solid article on using Cilium to enforce network policies in Kubernetes
==

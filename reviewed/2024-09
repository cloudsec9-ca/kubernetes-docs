
URL reference: https://www.youtube.com/watch?app=desktop&v=Ltf5cBzWlxU
DateReviewed: 2024-09-01
Description: This vid covers eBPF in about 2 minutes. First, we start going through the Linux kernel, and how it works at a basic level. Then, they pose the question - what if we want to change something in the kernel, and go through why we might want that. They say changing the kernel is hard, but we can use this cool thing called eBPF to do it. They then explain how eBPF programs are run inside a kernel VM. Basically, the VM system allows the compiler/toolchain to verify what is being done by the eBPF program, to ensure it only does things we want it to. High level but informative, this is a great intro to eBPF.
BottomLine: Great 2 minute intro to eBPF in the Linux kernel
==
URL reference: https://www.armosec.io/blog/ebpf-reverse-engineering-programs/
DateReviewed: 2024-09-01
Description: It seems that instead of using kernel modules, many companies are now using eBPF to do kernel related actions, and this article will look into that and how to break down a program that is intended to be run by eBPF. We start with an intro to eBPF, explaining how using eBPF is similar to a kernel module, and how it is run with a JIT compiler and in a sandbox environment. A verifier checks the program before running, constraining what can be done. To actually run a program, you need to have your code compiled by a compatible complier, and Clang is a popular option. The VM that is used contains registers, and they break down how they are divided up and what they do. They also go through the layout of Opcodes and a few examples so you can understand the layout. They then describe how you would actually get a BPF program to run, and how the kernel actually handles this. We then go through some of the setups and use-cases for eBPF. They note that a BPF program has access to and the potential to change privleged information, so care must be taken; they also note that there is a tight stack limit which must be kept in mind. They explain that eBPF is primarily event based, so the prinicipal way it interacts is to register hooks that get called with info passed to them. We have a diagram showing the call flow of various processes. They then spend a section explaining the verifier and how it works, breaking it down in detail, as it adds some quirks to how the flow works in an eBPF program. We finally arrive at reversing, and they pick a rootkit and go through an example. They find where it hooks, do a simple disassembly and step through, explaining all of the lines. They work through macros and function calls, breaking it all down. After the analysis, they explain that this program modifys and logs program execution. They then show the original source. What a great read.
BottomLine: Fantastic intro to eBPF and eBPF reversing
==
URL reference: https://chanaka-supun.medium.com/demystifying-service-mesh-on-kubernetes-533ec9974626
DateReviewed: 2024-09-02
Description: This article will talk about service mesh, and we start with a diagram, so that is promising. Next up is the motivator, why do we need a service mesh. They point out that a monolith runs all code in a single binary and can simply invoke a function call, where microservices might need to call out to each other to achieve the same call, needing network communications to work. There are a number of concerns, including security, capacity, availability and authentication. A service mesh can help bring these under control. Next up we dive into what is service mesh, which seperates networking parts from biz logic parts. One container does the network, and another the biz logic, but all in one pod -- the sidecar pattern. We then dig into how service mesh does this - starting with predefined policies for security and routing. The mesh creates the sidecar when a pod is created, and handles all of the setup/redirects for the logic container. We then look at some  Mesh providers, namely Istio and Anthos. They do a bit of a deeper dive on Istio, explaining how the different pieces work. We conclude with a demo of service mesh on GKE, utilizing a small e-commerce app. We then pivot back and cover traffic management with Service mesh. Overall a decent piece, just oddly organized.
BottomLine: Interesting piece explaining Service Mesh on Kubernetes, with a simple demo walkthrough
==
URL reference: https://medium.com/@sudhakarak30/end-to-end-ci-cd-pipeline-implementation-36713766f923
DateReviewed: 2024-09-03
Description: So, this is a walkthrough of setting up Jenkins. It's broken down into steps, and there are a LOT of them. Like, too many (39 parts) -- I think breaking this into a couple broad parts might have been a bit more approachable. We start with a diagram, always a bonus. There is a long list of prereqs, and a bit of background on the author using Minkube to deploy a Java app. Then, we're into the steps. The steps are all small, and they include screenshots or output as needed. The first few steps is firing up VMs and prepping, followed by installing and getting Jenkins to run. Next is configuring Jenkins through the web UI, and installing some plugins for the build process, like Docker. Then we go through the process of hooking up a Docker hub account to Jenkins, to action the build process. We pause for a primer on Jenkins stages, so you know how the build flows; we're up to part 26 at this point. Next they go through spinning up Kubernetes and ArgoCD, and they end with a Java spring boot app built using Maven. Pretty impressive.
BottomLine: Longish but detailed walkthrough on setting up Jenkins with Kubernetes
==
URL reference: https://fenyuk.medium.com/kubernetes-operator-create-the-one-with-kubebuilder-5d1ac240d0d4
DateReviewed: 2024-09-04
Description: This article talks about how Operators can be used to customize Kubernetes, and how to actually build them to accomplish this. In the early motivation, it talks a bit about how the pieces play together and what the Operators high level role here is. We start with a reference URL to an intro to Kubernetes Operators, as the article intends to focus on development. To get started quickeer, he's going to base his dev on something he did in a previous installment, which he also references. Interestingly, the approach here is to help facilitate testing, namely tuning an app to have the right memory limits based on a load, which is being load tested with the purpose of eliminating out of memory errors. The intention here is to use the Operator to tune this; if a pod/container dies with an OOM error, bump up the memory limit and ENV info and try again. Gotta love the diagram, explaining the flow. He does note that this is probably not a best practices, but it is an interesting approach and usage. He then explains what is needed; namely a CRD or custom resource definition, to set up a memory limit, and a CR or custom resource to actually define that limit, along with an app to test it on and an operator to manage it. He'll use Kubebuilder as the dev tool. He assumes we've successfully installed Kubebuilder already, so only has to initialize and configure a new project to get started; it sets up the strtucture and gives us some sample Golang code and scripts. He shows the output, and then walks through configuring the CRD in the operator code and walks through the generated YAML file. Next up is the CR with a specific limit, which will actually be used in our pod. There is some CLI bits which deploy this into our K8s cluster. He adds some code to log for the Operator, and then deploys this to make sure the Operator is working in our cluster as we desire. Once this is done, he adds some code to actually do the memory bump if we got an OOM error, and adds it as a call from the code we've already deployed, and also mentions this is run once a minute. He then runs his load simulator and watches the output, showing the pod hitting an OOM error and the Operator bumping up the memory limit to try again. Overall a good walkthrough showing a few different areas of how Kubernetes works along with deploying and using an Operator.
BottomLine: Great hands on for Operator development showing a few areas of Kubernetes pretty well
==
URL reference: https://medium.com/@subhamchand200/kubernetes-with-helm-kubernetes-for-absolute-beginners-772f4bb84aec
DateReviewed: 2024-09-05
Description: Kubernetes can be overwhelming to those who are new, despite it being a very popular and emerging app deployment option. The author argues that using Helm can bring down this barrier and make Kubernetes more approachable. We start with a quick background to what K8s is and a blurb about how it's managed and what it does. We then dive into a list of K8s features, like orchestration, self healing, discovery and so on - a list of 5 with a solid sentence each. On to Helm, which is positioned as a package manager like Yum or Apt for Linux distros. We get another 5 part list, where versioning, config/dependency management, charts and releases all make an appearence with our same one sentence summary. Next up is a pitch for using Helm with K8s, which is a 4 part list which boils down to simpler and easier overall. We have some prereqs, including basic knowledge of containers, a K8s cluster and a Helm install; but apparently we're going to help. Yes, we actuall go through a Helm install, and also a K8s cluster, but curiously we tackle Helm first and then K8s. Once we're here, we add a Helm reop and finally deploy a chart to verify the install. Weirdly, there seem to be CLI commands, but they aren't denoted as such, so I'm not sure how a beginner would follow this. We then run this on our K8s cluster, getting an Ingress app deployed. We now come to a spot where we get into some "advanced" Helm features, including rolling a chart of your own so you can deploy your own app. My take is while there are a few hiccups, this is a good piece overall. It feels like it was written in one environment though and translated over to medium, without doing the markup needed to have code blocks. Worth a read, but probably not the best intro.
BottomLine: Decent Kubernetes with Helm for beginners intro with some formatting challenges
==
URL reference: https://dev.to/prodevopsguytech/kubernetes-commands-for-devops-engineers-124o
DateReviewed: 2024-09-06
Description: After an extremely short background paragraph, this piece is a speed run through the core and many useful commands and concepts related to Kubernetes clusters. We start with a small key concepts section, and then dive into the beginner commands. This includes cluster info, namespace management, pod management, deployment management and service management. Each section presents 2-4 commands with an example. They do the same for intermediate and advanced commands, building up a solid stable of commands that can be used. To close, they do talk about a few best practices, but there are 5 short sentences devoted to it. Overall it's a good reference, but without a bit more context it might be hard for a beginner to leverage this.
BottomLine: Great reference to Kubernetes commands but lacking context for a beginnner
==
URL reference: https://www.sharepointeurope.com/decoding-azure-security-with-azure-file-share-mount-on-aks-workloads/
DateReviewed: 2024-09-07
Description: This piece starts with the claim that Azure security can be complex, and it is important to understand the fundamentals. We start with a crude diagram, and a story about sharing an Azure fileshare with an AKS cluster. Now they mention for various reasons what they couldn't use, they ended up settling on Workload identity. They include a decent diagram on how this flow works. We then are treated to a walkthrough of the steps they performed. We start with a bunch of enviroment variables, and then a CLI command to enable this kind of auth in AKS. There are a few more steps to get the basic auth all set up, then settimg up the perms so that the actual SMB share can be accessed. There is a bit more K8s stuff needed, which is an ID to access and finally a storage class to wrap the actual share (optional), and a persistent volume to surface the share in K8s. To actually use this, we now need a PV claim for the pod it should be used on and then to snag it. So, while conceptually this makes sense, it would need a few more diagrams and maybe a bit of video to actually make it comprehensible.
BottomLine: Walkthrough of mounting an Azure drive to Kubernetes with AKS
==
URL reference: https://dev2ops.hashnode.dev/security-in-terms-of-containerskubernetes
DateReviewed: 2024-09-07
Description: So, different cloud providers have various tools for K8s stuff, so our author proposes using a custom K8s client for each task. Small diagram, yay, but then a few pieces - I think he's building a security wrapper, but doesn't describe it much. There are 6 pieces, and it's all point form; so done quickly. Could be good, but isn't too substantial.
BottomLine: Bit too quick for a security piece.
==
URL reference: https://securityboulevard.com/2024/01/mastering-kubernetes-in-on-premises-environments/
DateReviewed: 2024-09-07
Description: Kubernetes is the cornerstone of cloud-native tech; we do a bit of a dive into private clouds, including a chart. They argue that on-prem K8s is not a variation of the public cloud version, but a specialized revision for the on-prem world. We then get to a list of benefits, which strangely seem very similar to the in-cloud versions. And now we actually dig in and talk about issues with the on-prem versions - think like no cloud vendor management, hardware management and networking complexity. Lastly, there are storage considerations to take into account. We do take a quick tour through the many tools to help with networking, storage and extensibility that might be a consideration in an on-prem deployment. They also contrast full Cloud service providers to spots that do Managed Kubernetes services, like Rancher, OpenSshift and vSphere. They also talk a bit about smaller companies that are providing solutions in this space. We're now taken on a tour of features these Managed K8s providers might provide, like streamlined installs/upgrads, security, multi-cluster support and general K8s support and expertise. We then walk through some high level approaches to K8s management, focused on security, like etcd encryption, hardening the API server, and good kubelet configuration practices. They also touch on TLS, along with proactively managing security vulns, adding admission controllers to enforce security policies, and perfroming security assessments. Overall, a good read. 
BottomLine: Decent read on various on-prem Kubernetes issues and approaches
==
URL reference: https://7wdata.be/devops/cloud-native-security-and-performance-two-sides-of-the-same-coin/
DateReviewed: 2024-09-08
Description: Our article poses the interesting question -- should you have a patch to a Prod Kubernetes system, how long should that take to roll out? They argue that microservices are ephemeral, but even being fleeting can be dangerous if the moments it is working are unpatched. A good DevOps process can release code weekly, daily or even hourly, which they argue reduces risk. They also link security to performance, in that both of them require similar approaches in monitoring and ability to turn things around. They further argue that good performance monitoring can alert to things like DoS attacks. They point out that traditionally, there was a multi-step process for rolling out patches, which might take up to a few weeks, while leaving systems open to potential attacks. They do point out that patches are risky because of unknown interactions, and that is why the testing and delays happen. We then come to a handwave, where "cloud native principles" solve all the issues, so use Kubernetes? My take is this starts out strong, but doesn't explain WHY the cloud native principles are so strong -- you can test on a subset, you can easily roll back if you hit an issue, etc. But the fact that I'm saying it and they didn't is the issue.
BottomLine: Interesting premise that doesn't follow through in the end - best to skip
==
URL reference: https://techcommunity.microsoft.com/t5/microsoft-defender-for-cloud/leveraging-azure-native-tooling-to-hunt-kubernetes-security/ba-p/4217705
DateReviewed: 2024-09-08
Description: This article is the intro to a way to figure out if our containers are different than we deployed them. They are looking for something called binary drift, where deployed containers are different then the images they were created from. They aim to build understanding of the security risks of binary drift, figure out how to detect drift, and finally prevent such drift from occuring in the first place. This is all happening on Azure and AKS, and they set out some base assumptions they have. They show how to configure Defender to look for drift, and also point out that by default, it is set to ignore drift in the rules. Overall an interesting topic.
BottomLine: Good intro as part of a series on Azure drift detection in Kubernetes
==
URL reference: https://itnext.io/choosing-the-perfect-kubernetes-workload-a-practical-guide-for-application-success-fe905c40788a
DateReviewed: 2024-09-08
Description: This article is about choosing an optimal Kubernetes workload - I don't know what that means exactly, but I guess we're going to find out! We start with a mind map, which is an interesting way to illustrate things. We then walk through a number of K8s concepts, like Deployments, StatefulSets and DaemonSets to name a few. Ah, what they mean is that you should use the K8s resource that matches the pattern of the app you are deploying. So, for instance, for a web application, they use Deployments. The explain why they think this is a good resource, along with an example walkthrough including a YAML file. They talk about a new to me resource, PodDisruptionBudget, which is a way to ensure a minimum number of pods during things like maintenence. They also go through a detailed example of dynamice scaling. I'm going to stop here, but they don't -- they go through several patterns, in lots of detail. Honestly, this is a hidden gem, and I'd for sure put this on the must read list.
BottomLine: Odd title but excellent article on various ways to run and control apps in Kubernetes - recommended
==
URL reference: https://cloud.google.com/blog/products/identity-security/create-a-powerful-kubernetes-security-duo-with-custom-org-policy-and-policy-controller/
DateReviewed: 2024-09-09
Description: This is an interesting control, from Google on their GKE Kubernetes line, to enhance what things can be allowed or restricted at a high level. They point out you can use Custom org policies to centralize controls and standardize them, creating guadrails. They talk about what they are able to do and how to craft them at a high level, and point out they can be org, folder or project in scope. They come with things like simulation and dryrun, to preview violations and identify runtime issues. They go through a number of things the policies can restrict or enforce, like making sure clusters have an identity or requiring logging. They then dig into Policy controller a bit, which is guardrails for policies. You can have it in dryrun, warn or enforcing mode, and can use it to ensure security and governance concerns aren't violated. They talk about policy bundles, which you can use to craft your policies and 80 templates to get started with in their library. They go through a number of scenarios you might use them. Finally, we get a discussion of when and how to use the two different systems. And we get a diagram -- basically Org policy is overall, and Policy controller is at the fleet or cluster level. Interesting high level walkthrough.
BottomLine: New tool aimed at Google Cloud Kubernetes for more layed approach to security and governance control
==
URL reference: https://rad.security/blog/security-features-in-kubernetes-latest-version-1.31
DateReviewed: 2024-09-09
Description: This article will take a look at new security improvements in the latest version of Kubernetes. The first one they dive into is around anonymous access -- by default, K8s can be very open, and an attack last year leveraged this default openness to launch workloads for cryptomining. The new mechanism only allows specific endpoints to serve anonymous requests, meaning even if your RBAC doesn't restrict it, it won't be processed if it isn't in the allow list. The next feature they talk about is SupplementalGroups, and what they can do. They point out this is now controlled at two levels -- OCI and K8s API, and this can create a gap that allow a container access that isn't intended by the cluster owner. This new feature adds an API field that specifies the exact levels and allows inspection, ensuring containers get the right permissions. Next up is enhancements around service accounts. As they are mostly used by apps, service accounts are often neglected or forgotten in the overall scheme of things. The new feature allows binding to the token info like where the access request came from originally, simplifying things like ensuring a match to the current requestor. Next up is improvements in the kube-proxy handling; we start with a bit of background on kube-proxy and move onto how it is handled. They talk about ipvs and iptables, and how iptables has some issues, and the intent is to replace it with nftables and provide a migration path. Next up is using field or label selectors for authorization decisions, basically making that path more flexible. There are a coupe file related ones -- one is a fix that makes read-only mounts truly read only, the other is split image, allowing the image/readable layer to be split from the container/writable layer where kubelet writes its temporary files -- the idea here to up performance on the write bits by seperating them more formally from the underlying non-changing bits. Rounding it out is AppArmor support, profiling support in kubectl debug and service CIDRs that have entered beta. Overall, a bevvy of features!
BottomLine: Good overview of new security related features in Kubernetes 1.31
==
URL reference: https://itnext.io/kubernetes-the-art-of-zero-downtime-deployments-fa92c8ec5646
DateReviewed: 2024-09-10
Description: Downtime is bad, but Kubernetes offers a way to do things with no downtime. You need to have a proper approach and strategy for this to work. We have a mindmap again, but targeted towards types of updates. We dive right in, starting with the built in rolling updates, where you specify the number of replicas and K8s does all the work. We take a sidebar where they explain how we target pods in a Deployment - namely, labels. Thus, the tagged or labelled pods are the ones to focus on. We move back to deployments, and talk a bit about rolling updates, with an example chat app. They dive into a bit of the settings here, but the important part is we have to specify we want one pod always available. We then run the rollout, and we can issue CLI commands to see the status and when the rollout completes. They explain what happens if a failure in the new version occurs, and how you can have an automatic rollback. We now move onto a more straightforwad deployment technique, which just stops the pods and creates new ones; this involves downtime, and they target this at the dev environment. They talk about some strategies, including graceful shutdown, to ensure as little impact to users as possible. They also touch on readiness probes, what they do and how they work. Now we move onto other deployment types, like blue/green and canaries. We start with a diagram for the Blue/Green, and then continue with a discussion of how this progresses. Then we pivot to Canary, also starting with a diagram. We also go through how a Canary deployment works. For both types, the new version is rolled out in the background, and after a criteria is met switched to. With B/G it is usually an internal test, while with Canary it's a small external one. They discuss some other deployment types, including Argo, hybrid and a few others, talking about the pros and cons of each. Overall, a great piece and very well rounded.
BottomLine: Great piece talking about minimizing downtime by using various Kubernetes rollout strategies
==
URL reference: https://cilium.io/blog/2024/08/14/hubble-for-network-security-and-observability-part-1/
DateReviewed: 2024-09-11
Description: Kubernetes is the defacto orchestrator for containers, but there is complexity in them there hills. So we are going to see how Hubble and Cilium can help simplify stuff. We start with a primer on what is Cilium, which they go through some of the features at a high level. Next is Hubble, which is the observability layer for Cilium, allowing you to see the network traffic Cilium is processing. Again, we get some high level features. They position it for network security, and argue it is strong because of native K8s integration, eBPF powered performance, deep visibility and API aware visibility and security, which they have a sentence about each of. They link to docs and intros, as well as labs and ways to use Cilium even if you don't want to replace your current CNI. We then get 5 real world testimonials, to help motivate us on our choice. An interesting piece.
BottomLine: Piece that argues using Cilium and Hubble for your Kubernetes network security needs in a pretty compelling way
==
URL reference: https://www.cncf.io/blog/2024/07/23/authentication-vs-authorization-understanding-the-difference/
DateReviewed: 2024-09-11
Description: There are two key concepts in allowing access to data and apps - authentication and authorization. This piece will try to break them apart. We start with Authentication, which they stylize as AuthN. Basically this is "who are you", with a bit of proof. Most commonly user/pass, can encompass things like MFA or biometrics. Next up is authorization, styled AuthZ. Here we know who you are, but we have to figure out what you should have access to. In K8s context, this is primarily through things like RBAC, but Attribute (ABAC) can also come into play. We then go through a bit of discussion about how they work together to do what they need to do. They talk about sequence (authN before authZ), and how it is critical that each is strong and that helps the other. They also talk again about what they each mean and do. They then take us through a real world example, talking about logins and then what we can do on a social media site -- we can change our profile, but not others, for instance. Finally, some pointers on choosing the "right" solution -- things to consider like scale and flexibility, best practices, and finally the possibility of outsourcing complexity. A good understandable walk through this topic.
BottomLine: Intro to the difference between Authentication and Authorization and their impact on security
==
URL reference: https://medium.com/@nbryleibanez/how-to-deploy-a-containerized-django-application-in-a-local-kubernetes-cluster-5f2a0bbf23a0
DateReviewed: 2024-09-12
Description: First, we start with a bit of a backgrounder on microservices, and how Docker and Kubernetes play a role, and they explain how resilience, scalability and ease of deployment are all made better. We then start with a ref to K8s and Docker documentation, and we do a quick primer for both Docker and K8s. Next up we go through a list of pre-reqs to get going with the tutorial. They then dig in, by explaining we'll deploy a simple Django project to get the idea of what is going on. After creating a directory for our dev, we then fire up a virtual Python env to allow us to build up our various libraries and dependencies. We then use PIP to install Django and Uvicorn, and finally create a Django project. We then grab our current dependencies and create a requirements.txt file with them. We then do some simple configs, and they show us the full settings.py as a screenshot. We also have to tweak urls.py, to reference local files. Finally, we set up the static files with a Python CLI command. They then run uvicorn to fire up a web server and show our Django app is working. We now pivot to creating an image, so they show us the Dockerfile we will need to build the initial container, and walk through it line by line. They then execute the CLI command that will create the Docker image from the CLI, and explain it. They then show us how to check on the image in Docker, and then run the container. They show us some ways to get info from Docker, including logs and container status, and explain howo we can access the new app. Once we confirm it works, they give us the CLI to spin down the container. We then run through putting the image into a repo, namely Docker Hub. We then run through how to use K8s to snag the image and run it as a pod, and how to verify it is running. To tie it up, they show how to spin down the K8s resources. It's a decent walktrhough for a Python person new to containers.
BottomLine: Solid tutorial on getting a simple Django app running as a microservive on Kubernetes
==
URL reference: https://itnext.io/terminating-elegantly-a-guide-to-graceful-shutdowns-e0dcd9940f4b
DateReviewed: 2024-09-13
Description: This article will talk about how to do graceful shutdowns in the container world. In real life, pulling the power plug out of a computer should be avoided, as modern systems have all kinds of things they need to save before powering off. This piece will try to show how to do the nice kind of shutdown in the container world. We start by going through some Unix terminology, and the one we'll be looking at is SIGTERM. So we're going to examine a toy GO app, built just to figure out how the graceful bits should work. We then get a link to a repo with all the code, and they explain what we need - Redis and Go apps on Kubernetes, a traffic generator, a way to push K8s to stop a pod and a way to verify our generator traffic is all accounted for. We start with a Go program, and then test to see we are losing requests when we do a normal termination. We then go through the process of capturing signals in Go, and then rewrite our original bits to do so properly. They then go through each of the changes and explain what they do -- which is to stop gracefully while handling the last requests. We verify, and all requests are captured. Helpfully, they don't stop there, but actually give context around what is going on. They explain that your pod is first set into "terminating" status, telling the loadbalancer to stop sending it traffic, and then a hook is run and then a SIGTERM is sent to your container processs. If, after (a default of) 30 seconds your app doesn't finish, K8s will take more drastic measures. Overall a great walkthrough!
BottomLine: Awesome walkthrough of using graceful shutdown in Kubernetes pods
==
URL reference: https://cloudnativenow.com/topics/containers/kubernetes-turns-10-heres-seven-ways-to-make-it-better/
DateReviewed: 2024-09-13
Description: On the 10th anniversary of Kubernetes, this article will give us seven ways to make our experience better. It's short and very high level, but does a good job with it's approach. Each recommendation has a paragraph of explaination, making it decent sized. The areas covered are simplified resource management, enhanced UX in CLI and GUI, advanced automation and smart defaults, simplified networking and storage, intuitive security and compliance, better observability and troubleshooting, and finally enhanced ecosystem integration. Not bad for some general things to tackle.
BottomLine: Decent high-level piece on 7 things to make Kubernetes better
==
URL reference: https://securityboulevard.com/2024/08/runtime-anomaly-detection-in-kubernetes-enhancing-security-through-context-aware-profiling/
DateReviewed: 2024-09-14
Description: This piece just dives right in, claiming that runtime anomaly detection is becoming a critical component to protect container environments. We dig into why traditional approaches with runtime detection cause problems -- namely, too many false positives. This in turn causes alert fatigue and difficulty in finding true threats. They say this is due to the generic rule sets typically used, which aren't tuned for a specific workload. They talk a bit about why this is and how a one-size-fits-all approach won't work. Instead, they tout a new container-focused approach, pioneered by ARMO, which uses 4 approaches. First is app profiling, where using eBPF we can understand what processes, files, network activity and even sys calls and permissions are needed. Second is contextual learning, which observes patterns over a set period (usually 1 day) to figure out what it does. Third is anomaly detection, but informed by the profiling and learning to reduce false positives, and finally behaviorial inspection, to find things like in-memory execution or reverse shells. We're then treated to a short benefits section, which includes no config, better security posture, flexible alerts and reduced false positives. They then do a high level practical example, with a diagram, illustrating how this might work out in the field. A pretty good high level intro to this topic.
BottomLine: Decent high-level treatment of using runtime anomaoly detections practically to help secure a Kubernetes cluster
==
URL reference: https://medium.com/@sagar.parkar29/31-smoothly-upgrade-your-kubernetes-cluster-with-kubeadm-a074a444f20c
DateReviewed: 2024-09-14
Description: This is a short hands-on walkthrough of upgrading your Kubernetes cluster software. They have a seven step CLI process, which is ideal for development clusters. We're going to focus on the kubeadm tool here, and we start the section here with a reference to the official docs. Diving into the actual upgrade, the first step is to spin down the pods on the target node, which they do by running a drain on it. Next they run the system level upgrade of the K8s software, but keep kubeadm at the current version. Step 3 is to run kubeadm to give us our options - what is available, where are we at, so we can decide. Finally we apply the upgrade to the control plane node, and then to the worker node(s). If all goes well, we now upgrade the kubelet and kubectl binaries, to get everything in sync. Lastly, we "uncordon" to allow the nodes to schedule pods again. Simple, understandable, and helpful.
BottomLine: Great simple walkthrough of a CLI Kubernetes software upgrade
==
URL reference: https://pentera.io/blog/kubernetes-attack-surface/
DateReviewed: 2024-09-15
Description: For something called the Kubernetes attack surface, there is a long preamble on what K8s is and why it is important, so I'd say audience focus here is sec pros and not DevOps people. They have some good broad strokes, talking about container escapes, lateral movement and priv escalation to start. Then we do a side quest into application access tokens, with config file snips. We then talk a bit about cloud providers and control planes, risk calcs, before doing a walkthrough of an actual exploit. While there is some good material here, the piece isn't sure if it's high or low level, audience or focus. So, read for what you want.
BottomLine: While there are some good security snippets, the piece lacks focus and clear audience so should be skimmed until something pops out at you
==
URL reference: https://adamtheautomator.com/kubespray/
DateReviewed: 2024-09-15
Description: This piece tackles setting up a production-ready Kubernetes environment. Actually a great idea, it uses an Ansible Playbook to deploy your cluster. It's a walkthrough, so it needs a few Linux servers to play with. It's step by step, so you first start with some installs - first, just a general update, then Git and Python, and then the repo for Kubespray. We then run the Python bits there that bring all of the Python dependencies down. We're now doing our K8s setup, and they start by copying a sample inventory over to get started. They do some config file massages, and finally action things as an Ansible playbook. Once things are done (they say this can take 20+ minutes to work), we verify things are working. They do some K8s configs, and then even take us through a sample deployment. Overall a great walkthrough.
BottomLine: Solid walkthrough to create a production ready Kubernetes cluster
==
URL reference: https://developers.redhat.com/articles/2024/08/08/getting-started-operatorpolicy?sc_cid=7015Y000003sfSaQAI
DateReviewed: 2024-09-16
Description: This is a technical article to motivate devs to try new options and features, in this case OperatorPolicy. We dive right in with the new features, which start with fewer required features (maybe more defaults?) to make using it easier. They also include control of updates and alerts, and tools to uninstall things. Next they go into a bit of detail, explaining how some of the ease of entry features are positioned. They include YAML snippets and go into the various things like the upgrade control -- it can be none or automatic, for instance. They walk through how to view the effects of your policy, and even how to see the YAML that creates the policies. They dive into a bit about how to allow a new version, how to figure out where and when it can be installed, and  what it affects. They then go through the cleanup piece, which includes uninstalling. Overall a good piece explaining the new features.
BottomLine: Tech piece explaining new features of OperatorPolicy for Kubernetes
==
URL reference: https://collabnix.com/whats-new-in-kubernetes-1-31-release/
DateReviewed: 2024-09-16
Description: This article is going to go through the features of the newest Kubernetes release, v1.31 "Elli". We dive right in with some network reliability enhancements, specifically parts to help with load balancing. We also get nftables as an option for kube-proxy, with more flexibilty as a result. They also talk about multi-service CIDR and traffic distribution. Pivoting to security, AppArmor support is now GA, and Service account tokens get an improvement. Over in storage, there is a few things going on - some base improvements, along with ModifyVolume being available as a beta. There are also some AI/ML and hardware management features, along with Image Volume support. Overall a busy release!
BottomLine: Good overview of the new Kubernetes features in v1.31
==
URL reference: https://medium.com/@itsmedaminichadha/from-docker-to-kubernetes-understanding-the-evolution-and-architecture-of-container-orchestration-6a4a905c0d1d
DateReviewed: 2024-09-17
Description: We start from the basics - Docker changed how we package and deploy apps, but Kubernetes changed how we orchestrate things. We dive in talking about how Docker basically invented containerization as we know it, and then we go through a few of Dockers strengths - consistency and isolation. We contrast that with the limits - namely no scaling, healing, confinement to a single host and limited enterprise features. We then pivot to Kubernetes, with its clustered arch, scaling, auto-healing, and enterprise friendly features. They talk about the multiple runtime envs that K8s supports, like dockershim but also containerd and other KCI compatible binaries. They have a comparison chart, to show what features K8s and Dcker have. Finally, we dip into K8s architecture, including a diagram of a typical cluster layour. They take us through the control plane and worker side, and explain how pods are what our cluster is running. They have a paragraph on how this works together, and tie things up with a quick comparison of Docker and K8s networking; Docker ties into one host, where through kube-proxy K8s ties into the entire cluster.
BottomLine: A well done compare and contrast between Kubernetes and Docker
==
URL reference: https://cybersecuritynews.com/new-kubernetes-vulnerability/
DateReviewed: 2024-09-18
Description: This article reviews a 2024 CVE that targets the Nginx Ingress controller in Kubernetes. As we first dive in, they surface the key terms - annotations, which attaches metadata to objects, and this allows behavior of the ingress controller to be configured. The flaw allows a bad actor to alter some of the annoations without proper validation, potentially allowing arbitrary commands to be executed, which is pretty serious. They do a technical walkthrough, but they also include an example, where by setting headers to include they can actually return webpage contents to clients, which shouldn't be possible. They then include a number of mitigations, the simplest of which is to simply upgrade the affected packaage. It's a good practical walkthrough of a CVE, with simple examples and good mitigations.
BottomLine: Great treatment of a current Kubernetes CVE with Ingress explaining the impact and mitigations
==
URL reference: https://www.linkedin.com/pulse/what-you-should-know-autoscaling-kubernetes-david-essien-40yxc
DateReviewed: 2024-09-19
Description: Our article will deal with the topic of autoscaling in Kubernetes. We start with an excellent example of a party, where we expect 500 people to attend, so need to get chairs/tables/placesettings and food for them. But if only 200 people show, we've got extras; so they mention that a vendor nearby will rent you items on a usage-based basis, so you can reserve for say 300 and whether 200 or 600 show up, you pay for exactly what you use. We now dive into vertical scaling, with a bonus diagram. Vertical scaling changes the footprint you are running in - like moving from 1 CPU with 1GB of memory to 2 CPUs with 3GB of memory, like an upgrade. Contrast this with horizontal scaling, where instead of a bigger machine we get a second similar sized machine, so you distribute requests to different machines to balance them. We then look at a cluster autoscaler - where we were talking about apps running directly on VMs before, now we're talking about something like Kubernetes, and start with one physical node, which is running 4 pods. If we need more pods, we might need another physical node added -- in this case, adding or removing a pod doesn't directly correspond to nodes or VMs like before. They do talk a bit about resource constraints and affinity rules, as well as having a few diagrams and some YAML to help tie things together. They do talk about some of the benefits of autoscaling, like cost savings, minimized downtimes and proper management of various resources. They also talk a bit about issues and pitfalls, and recommend some ways to do things. Overall a great intro to Autoscaling on Kubernetes.
BottomLine: Good approachable intro to autoscaling on Kubernetes
==
URL reference: https://dataprophet.blogspot.com/2024/08/kubernetes-security-best-practices.html
DateReviewed: 2024-09-19
Description: So this article isn't general Kubernetes practices, but rather focused on the build side of the container image. They have a number of main topics that they talk about, with some bullet points and a few sentences of clarification thrown in. First they mention building small container images, including starting with a minimal image and only adding what is needed. Next they talk about things like keeping images up to date, and building immutable images, which both reduce security attack surface. We then are taken through image signing and scaning for vulns, both of which helps to ensure we know what we're deploying and that we have confidence in it. 
BottomLine: Decent recommendations for building containers, but not that Kubernetes specific
==
URL reference: https://cloudnativenow.com/social-facebook/bouyant-extends-reach-and-scope-of-linkerd-service-mesh/ 
DateReviewed: 2024-09-20
Description: This article goes through updates Linkerd is getting from an advocate company, Bouyant. We dive right in with IPv6 support, zero-trust audit policies and better timeouts and per-route metrics. They also talk about a new ability for HTTP/2 keep alive messages. They also added JSON support for all CLI output, and new automations to add in workloads running external to Kubernetes - on a VM, for example. There is a bit more discussion of why they focused on these things and how this improves it's role in the service mesh ecosystem. Overall a decent piece.
BottomLine: Short article about Linkerd improvements for service mesh in Kubernetes
==
URL reference: https://kubeha.com/the-future-of-cloud-computing-kubernetes-at-the-core/
DateReviewed: 2024-09-20
Description: This article is a thinkpiece on the future of Cloud computing. They pose that Kubernetes is the future of cloud computing, and explore what this means going forward. They argue that K8s is a more efficient way to deploy and manage apps in the cloud. Traditional VMs are cumbersome and resource intensive, while containers can be lightweight. They cite a number of reason that K8s is robust, including being declarative, self healing and things like exentsibility and scalability. They then get into microservices, and argue K8s is a great spot for them becasue of things like service discovery and load balancing, among other features. They talk a bit about hybrid cloud and multi cloud, and the benefits of this. They handwave at IoT and Edge computing, before moving on to the ecosystem and the community, which are important pieces. We do look at the challenges, which are improving developer experience, enhancing security and integrating more with AI and ML. While this is an excellent background piece, it fails to actually articulate in any way about the future of either K8s or Cloud computing.
BottomLine: While a terrible piece on the future - does a solid job of providing Kubernetes background
==
URL reference: https://sysdig.com/blog/optimizing-wireshark-in-kubernetes/
DateReviewed: 2024-09-21
Description: This is a look at the classic network packet capture tool Wireshark, but through the lens of a Kubernetes cluster. K8s poses some unique challenges through it's more ephermeral nature, and the fact there is a lot of inter-pod/node chatter, which contributes to network noise. While Wireshark lacks K8s context, with Falco bridges some of that context is able to add info about K8s abstractions. They also argue that PCAPs, traffic mirroring or even Flow logs can incur costs in transfer and storage while amassing large bits of irrelevant traffic for security. They argue a new tool called Falco Talon can help, with it's cloud-native detection bits which also integrates with tahark, a terminal version of Wireshark. They go through the workflow - Falco is used to monitor and initiate things, looking for unusual traffic that might be of interest, like an Indicator of Compromise. Once found, it sends an event to the backend, allowing a script to be run in response, to for instance bring up tshark realtime to see what is going on right now. It can further initiated a PCAP file in the context of the unusual event, allowing later examination and review. This allows deeper analysis and true DFIR of the incident. They even have a little flow chart.
BottomLine: An interesting approach to network captures on Kubernetes
==
URL reference: https://www.zdnet.com/article/how-the-latest-kubernetes-release-now-handles-ai-workloads-and-more/
DateReviewed: 2024-09-21
Description: Kubernetes does a lot of things well, but this piece claims it doesn't manage CPU, memory and GPU as well as needed for AI and ML computing. The latest version of Kubernetes, v1.31 Elli, aims to help out with this. One feature touted is initial support for OCI images as a native volume, which they claim will help switch out LLMs easily. Another feature is updates to dynamic resource allocation, which they argue will add better handling for hardware accelerators like GPUs. They say this will improve autoscaling and things like AI which can use GPUs. They mention on the security front that AppArmor is now supported, as well as anonymous endpoint request blocking for the API. They have point-form info on three other features to round out the chat on v1.31 - Moving cloud integrations to external pieces, deprecations of non-CSI volume limits and Cgroups v1. Overall a decent toe-dip.
BottomLine: Good coverage of new AI friendly features as well as other new bits for Kubernetes v1.31
==
URL reference: https://priyadarshi.hashnode.dev/day-38-understanding-kubernetes-namespaces-a-comprehensive-guide
DateReviewed: 2024-09-21
Description: This article will go into what a Namespace is in Kubernetes. We start with a diagram which highlights a few concepts from Kubernetes. Our author defines it as "a virtual cluster within a physical cluster". The idea is to logically group different resources together for both organization and security perspectives. They talk about how you can use things like pods, services, reesource quotas and network policies in a namespace, as well as a short explaination of how each of them work. We go through the pieces of a namespace in more detail, with a bit said about resource isolation, access control, resource management and org strucutre in a namespace. We have an example YAML showing how to create a basic namespace in K8s. We do a more fullsome example, breaking our cluster into frontend and backend namespaces, to allow different teams to have access to different parts of the DB. We walk through the creation of the two namespaces, and then actually create and deploy apps in each one for each team. They even show how the backend team's app is exposed to the frontend team's pods through a service, with the YAML included. Simple and good walkthrough of using namespaces.
BottomLine: Intro to Kubernetes namespaces including a basic walkthrough.
==
URL reference: https://cloudnativenow.com/topics/cloudnativedevelopment/microservices-the-good-the-bad-the-clunky/
DateReviewed: 2024-09-22
Description: This article is going to dive into Microservices. Our author claims that microservices are super important, as it is a shift away from heavier monoliths which are tightly integrated and hard to change, to more lightweight and flexible systems communicating by APIs. They reference a whitepaper explaining that microservices can compose thousands of individual components. They concede that moving to microservices isn't simple -- there are no point and click approaches, and it's not a lift and shift approach. They author says the best candidates would be either brand new apps or older apps where only part of the app is to be turned into a microservice. There is an advantage for existing apps -- you know what works, and you have people you can ask about improvements or changes. Going further, the author points out microservices are more expensive infrastructre wise -- as we have more small services which all need a bit of resources -- for the advantage of being more robust and flexible. They explain that sometimes using a sidecar can help with things like auth and traffic management, letting the service focus on functionality. They mention that testing is both easier and harder -- each service can be independently testted, but also needs some testing as an integrated unit. Finally, they argue that clunky monoliths can be refactored into decent microservices with the right approach. An interesting thinkpiece.
BottomLine: Decent coverage of the benefits and pitfalls of microservices frequently used on Kubernetes
==
URL reference: https://findsec.org/index.php/blog/309-tls-bootstrap-attack-azure-kubernetes-clusters 
DateReviewed: 2024-09-22
Description: This article will dive into the TLS bootstrap attack against AKS. It seems the vulnerable service was the Azure CNI piece for Kubernetes. They detail the attack, which is simple -- asking a service called Azure WireServer for the key which protects some secrets, and then using that key to decrypt the TLS bootstrap token and the Kubelet client cert. This allows for access to all secrets and access to all workloads. They do have some mitigation actions, like adding NetworkPolicy restrictions, Auditing K8s clusters, checking for anamalous behaviour, and patching regularly. Decent coverage of this issue and good mitigation tips.
BottomLine: Talks about the Azure TLS bootstrap vuln targeting AKS/Kubernetes clusters
==
URL reference: https://www.wiz.io/academy/kubernetes-clusters-a-security-review
DateReviewed: 2024-09-22
Description: While titled as a security review, it's actually more of a primer and a security piece. First we go through the benefits of a Kubernetes cluster, and then the components, with a nice diagram. Finally we get to security, which is misconfigs, container vulns, net threats, secrets management, runtime sec, access control and data security. They have a pretty good 5 point approach to K8s security, with a diagram. Not a bad security bit.
BottomLine: Decent bit on Kubernetes security with a sizeable primer upfront.
==
URL reference: https://gauravbharane.medium.com/day-5-kubernetes-storage-and-security-ff4620d926a8
DateReviewed: 2024-09-23
Description: This is part of a week-long challenge series, and today's topic are Kubernetes storage and security. We dive in with a treatment of Persistent volumes, and the complementary PV claims, which make storage available and attach it to a pod. Each area gets a decent paragraph of description, and either key concepts or a YAML snippet. Next up are Storage classes and stateful sets, and both follow the formula of a decent paragraph and concepts or YAML. Now without any transition, we jump on to security in RBAC and then Pod Security Policies, with the same format as before. We tour sercrets manager and network policy before ending on TLS, where they talk about creating and storing the certs needed. Overall a decent but brief intro to two important topics.
BottomLine: Quick intro to both security and storage in Kubernetes
==
URL reference: https://medium.com/@serkanturan_79203/wordpress-kubernetes-deployment-74dcea8143c8
DateReviewed: 2024-09-23
Description: Our author is going to show us how to deploy WordPress on Kubernetes in a scalable and manageable way. There are thre pieces to this puzzle - WordPress app, MySQL database, and Persistent storage for the DB. We do a quick tour of K8s with some terminology and definitions, and then we're on to an arch diagram and explaination. We'll have a WordPress service, fronted by a load balancer. We'll have a pod which runs the WP app and connects to the DB. We need a ConfigMap for the WP config, and a PVC for uploaded content in WP. Finally, we'll need a pod to run MySQL, and another PVC for the database files. Okay, so that is it, no examples or repo, no YAML or details, just a high level walkthrough.
BottomLine: Disappointingly bad piece on deploying WordPress to Kubernetes
==
URL reference: https://www.altimetrik.com/blog/istio-service-mesh-pod-to-pod-security-isolation/
DateReviewed: 2024-09-24
Description: This article will dive into the traffic management aspect of Service Mesh on Kubernetes. They are using Istio for this purpose, which they note is open source. We get a diagram where they explain that Istio's service mesh is implemented in a two plane arch, with a control plane and a data plane, where the data plane is using sidecars to run the network portions. They claim that service isolation is a key to security, as it controls which pods can and can't talk to each other. They talk a bit about things going on under the covers, but one key point is all traffic is run throughh mTLS, which does both encryption and a level of authentication. They mention that by default, all traffic is accepted, but through using sidecar limits, traffic can be carefully controlled. They also go through an example with egress, and talk about using service registry to do restrictions as an alternate to the sidecar. A decent intro.
BottomLine: Mid-level intro to managing traffic with service mesh on Kubernetes
==
URL reference: https://itnext.io/using-the-kubernetes-resource-model-to-provision-cloud-infrastructure-dc8b75a4e328
DateReviewed: 2024-09-25
Description: The author has other Kubernetes posts, but this one is a deeper dive on provisioning cloud infra declaratively. We start with a bit of history, namely what was done when with K8s and also with Terraform. We then transition to how it works, and they use creating a Google storage bucket as an example. While they point out that there are lots of ways to get this to happen, they pose the question - can we do it from within K8s? You can, with a tool called Config connector, which leverages CRDs to create the underlying resources. We're shown the YAML needed, with a few added tweaks, to get the job done. With a CLI command and the aforementioned connector running, out pops our bucket. We next talk about the benefits, one of which is staying completely in the K8s tooling, and another is that everything happens on the server -- no client state to worry about. They mention that this can be subject to things like RBAC, dynamic admission controls and state-based policy constraints to control how properties get set. Next we look at challenges, there is the chicken and egg - how do you run your first cluster to provision the rest of the resources? They also point out issues like desired and observed state, which is important because we want just the changes to be implemented. They point out users of TF will be uneasy without a "preview" capability that is harder to do in this approach. They further point out that K8s controllers are tuned for frequent changes, where cloud resources are changed only occasionally, and you can burn through a lot of cloud API calls like this. They go through a few more issues. They finish up with the reality that while K8s is widely deployed, using it to manage Cloud resources is not.
BottomLine: Great examination of using Kubernetes to manage cloud resources
==
URL reference: https://spacelift.io/blog/kubernetes-devops
DateReviewed: 2024-09-26
Description: This article will cover DevOps as applied to Kubernetes. First, we start with a primer of what DevOps is, along with a diagram showing the phases a DevOps project goes through. Next up is a quick Kubernetes intro - one high level paragraph. Then we get into how to do DevOps with Kubernetes, and they focus on three areas - Deployment consistency, Collaboration, and Self Service. Each topic gets a couple paragraphs of coverage on each, and they are focused on tighter and easier turnarounds of code. Finally they bring up the why, and this is a seven point laundry list with a diagram. Each list point gets a paragraph of coverage. It's a decent piece but I think some of the why could be instead more of a hands-on for the how.
BottomLine: Decent piece on how to do DevOps in Kubernetes
==
URL reference: https://vrushankamin.hashnode.dev/beginners-introduction-to-docker-configure-images-containers-and-docker-compose
DateReviewed: 2024-09-26
Description: This article is a walkthrough on using Docker. We dive in with an examination of the differences between a container and a VM, which is good for beginners. They then talk a bit about Linux namespaces and cgroups, before explaining that Docker runs natively in Linux and any containers are bound to the OS they run in. We then do a run through upsides of Docker before digging into things like installation and terminology. We then do a quick tour of the Docker CLI, touching on networking and how to create a container. They go through logs and running in the container. Also touch on Dockerfile, Docker Hub and images. Pretty good intro.
BottomLine: Good intro to Docker for beginners
==
URL reference: https://medium.com/@edu.ukulelekim/what-is-difference-in-liveness-probe-readiness-probe-and-startup-probe-in-kubernetes-e116c4563c13
DateReviewed: 2024-09-27
Description: This article aims to tackle the difference between Liveness, Readiness and Startup probes in Kubernetes. We start with a quick principle - that Pods shouldn't be considered in service until all of it's bits are working well. To actually check this, Kubernetes makes available a thing called a Container Probe. A probe gives us a status for a test, and these tests fall into four areas - exec, grpc, httpGet and tcpSocket. Each have a different measure of success, and we are free to pick the most helpful one as our metric. Generally, they will give us success, failure, or unknown, where we can perform additional test. There are three different probe types, and we'll look at each in tern. First is readiness, and this is used to check whether traffic should be allowed to a newly started pod. The give an example URL they check, with params to keep checking. Liveness is used to ensure the pod is running well. If a pod dies, K8s will restart automatically, so this is more for processing issues. Finally, the startup checks to see if things have started correctly. This might be helpful for updating content or if some bunch of content needs to be cached. They do point out that startup takes first precedence, and readiness and liveness only run after the previous probe has run successfully. A good intro.
BottomLine: Decent intro to the various health Probes Kubernetes can use
==
URL reference: https://www.f5.com/company/blog/nginx/scale-secure-and-monitor-ai-ml-workloads-in-kubernetes-with-ingress-controllers
DateReviewed: 2024-09-27
Description: Since Kubernetes is the platform of choice for containers, the author's argue it is an excellent candidate for AI/ML workloads. In this article, they are going to focus on using Ingress to do AI/ML things. They argue that many things makes AI/ML hard to do, like tool sprawl or poor performance. They advance that using the F5 Ingress controller allows one to tackle a few of these challenges together, like load balancing, API gateway along with the normal Ingress capabilities. They claim you can use this for Model serving, experimentation, monitoring and security. While there are a lot of claims, this really feels like an ad more than a tech piece, as they don't provide much detail.
BottomLine: Best to skip this fluffy ad light piece
==
URL reference: https://medium.com/@sultan.hafsa99/kubernetes-for-beginners-89eeb2ee9dfc
DateReviewed: 2024-09-28
Description: So, I went in with low expectations, as most Kubernetes for beginners pieces are super lightweight, but this one is decent. Short, easy to read, and gets into the basics without getting super technical, it does a good job of an intro without too many frills. It includes a diagram and a couple of charts to help make things understandable.
BottomLine: Good basic intro to Kubernetes
==
URL reference: https://techreport.us/2024/09/01/openshift-an-open-source-container-application-platform/
DateReviewed: 2024-09-28
Description: This is a dive into OpenShift, a PaaS which helps developers deploy containers quickly. We start with a short list of flavors, including Origin, the community driven upstream, Online, the public cloud service, Dedicated, the cloud managed by RedHat and Enterprise for on-prem. For this piece, we're going to focus on Origin, but things will be similar for many. They talk about the REST API, CLI and web console as ways to access and configure OpenShift. They go through env setup, logging in (as dev and admin) and out, and finally how to check which user you are. We then dive into project management CLI commands, as well as how to roll out images as containers. They show storage (PVC) and resources creation with YAML. They then pivot to Minishift, which I guess is like MiniKube for more mainstream K8s distros. They walk through how to setup the env, check status and delete the VM. They do a quick piece on using REST API to do some things. We then do a quick review of ideas for app deployment, like from version control, building a Docker image, pushing to a registry and then deploying to the cluster. I think this is a good primer, but the could have done the hands on a bit more beefy to help someone get started.
BottomLine: Decent high level primer on OpenShift, with some basic hands-on commands
==

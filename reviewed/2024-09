
URL reference: https://www.youtube.com/watch?app=desktop&v=Ltf5cBzWlxU
DateReviewed: 2024-09-01
Description: This vid covers eBPF in about 2 minutes. First, we start going through the Linux kernel, and how it works at a basic level. Then, they pose the question - what if we want to change something in the kernel, and go through why we might want that. They say changing the kernel is hard, but we can use this cool thing called eBPF to do it. They then explain how eBPF programs are run inside a kernel VM. Basically, the VM system allows the compiler/toolchain to verify what is being done by the eBPF program, to ensure it only does things we want it to. High level but informative, this is a great intro to eBPF.
BottomLine: Great 2 minute intro to eBPF in the Linux kernel
==
URL reference: https://www.armosec.io/blog/ebpf-reverse-engineering-programs/
DateReviewed: 2024-09-01
Description: It seems that instead of using kernel modules, many companies are now using eBPF to do kernel related actions, and this article will look into that and how to break down a program that is intended to be run by eBPF. We start with an intro to eBPF, explaining how using eBPF is similar to a kernel module, and how it is run with a JIT compiler and in a sandbox environment. A verifier checks the program before running, constraining what can be done. To actually run a program, you need to have your code compiled by a compatible complier, and Clang is a popular option. The VM that is used contains registers, and they break down how they are divided up and what they do. They also go through the layout of Opcodes and a few examples so you can understand the layout. They then describe how you would actually get a BPF program to run, and how the kernel actually handles this. We then go through some of the setups and use-cases for eBPF. They note that a BPF program has access to and the potential to change privleged information, so care must be taken; they also note that there is a tight stack limit which must be kept in mind. They explain that eBPF is primarily event based, so the prinicipal way it interacts is to register hooks that get called with info passed to them. We have a diagram showing the call flow of various processes. They then spend a section explaining the verifier and how it works, breaking it down in detail, as it adds some quirks to how the flow works in an eBPF program. We finally arrive at reversing, and they pick a rootkit and go through an example. They find where it hooks, do a simple disassembly and step through, explaining all of the lines. They work through macros and function calls, breaking it all down. After the analysis, they explain that this program modifys and logs program execution. They then show the original source. What a great read.
BottomLine: Fantastic intro to eBPF and eBPF reversing
==
URL reference: https://chanaka-supun.medium.com/demystifying-service-mesh-on-kubernetes-533ec9974626
DateReviewed: 2024-09-02
Description: This article will talk about service mesh, and we start with a diagram, so that is promising. Next up is the motivator, why do we need a service mesh. They point out that a monolith runs all code in a single binary and can simply invoke a function call, where microservices might need to call out to each other to achieve the same call, needing network communications to work. There are a number of concerns, including security, capacity, availability and authentication. A service mesh can help bring these under control. Next up we dive into what is service mesh, which seperates networking parts from biz logic parts. One container does the network, and another the biz logic, but all in one pod -- the sidecar pattern. We then dig into how service mesh does this - starting with predefined policies for security and routing. The mesh creates the sidecar when a pod is created, and handles all of the setup/redirects for the logic container. We then look at some  Mesh providers, namely Istio and Anthos. They do a bit of a deeper dive on Istio, explaining how the different pieces work. We conclude with a demo of service mesh on GKE, utilizing a small e-commerce app. We then pivot back and cover traffic management with Service mesh. Overall a decent piece, just oddly organized.
BottomLine: Interesting piece explaining Service Mesh on Kubernetes, with a simple demo walkthrough
==
URL reference: https://medium.com/@sudhakarak30/end-to-end-ci-cd-pipeline-implementation-36713766f923
DateReviewed: 2024-09-03
Description: So, this is a walkthrough of setting up Jenkins. It's broken down into steps, and there are a LOT of them. Like, too many (39 parts) -- I think breaking this into a couple broad parts might have been a bit more approachable. We start with a diagram, always a bonus. There is a long list of prereqs, and a bit of background on the author using Minkube to deploy a Java app. Then, we're into the steps. The steps are all small, and they include screenshots or output as needed. The first few steps is firing up VMs and prepping, followed by installing and getting Jenkins to run. Next is configuring Jenkins through the web UI, and installing some plugins for the build process, like Docker. Then we go through the process of hooking up a Docker hub account to Jenkins, to action the build process. We pause for a primer on Jenkins stages, so you know how the build flows; we're up to part 26 at this point. Next they go through spinning up Kubernetes and ArgoCD, and they end with a Java spring boot app built using Maven. Pretty impressive.
BottomLine: Longish but detailed walkthrough on setting up Jenkins with Kubernetes
==
URL reference: https://fenyuk.medium.com/kubernetes-operator-create-the-one-with-kubebuilder-5d1ac240d0d4
DateReviewed: 2024-09-04
Description: This article talks about how Operators can be used to customize Kubernetes, and how to actually build them to accomplish this. In the early motivation, it talks a bit about how the pieces play together and what the Operators high level role here is. We start with a reference URL to an intro to Kubernetes Operators, as the article intends to focus on development. To get started quickeer, he's going to base his dev on something he did in a previous installment, which he also references. Interestingly, the approach here is to help facilitate testing, namely tuning an app to have the right memory limits based on a load, which is being load tested with the purpose of eliminating out of memory errors. The intention here is to use the Operator to tune this; if a pod/container dies with an OOM error, bump up the memory limit and ENV info and try again. Gotta love the diagram, explaining the flow. He does note that this is probably not a best practices, but it is an interesting approach and usage. He then explains what is needed; namely a CRD or custom resource definition, to set up a memory limit, and a CR or custom resource to actually define that limit, along with an app to test it on and an operator to manage it. He'll use Kubebuilder as the dev tool. He assumes we've successfully installed Kubebuilder already, so only has to initialize and configure a new project to get started; it sets up the strtucture and gives us some sample Golang code and scripts. He shows the output, and then walks through configuring the CRD in the operator code and walks through the generated YAML file. Next up is the CR with a specific limit, which will actually be used in our pod. There is some CLI bits which deploy this into our K8s cluster. He adds some code to log for the Operator, and then deploys this to make sure the Operator is working in our cluster as we desire. Once this is done, he adds some code to actually do the memory bump if we got an OOM error, and adds it as a call from the code we've already deployed, and also mentions this is run once a minute. He then runs his load simulator and watches the output, showing the pod hitting an OOM error and the Operator bumping up the memory limit to try again. Overall a good walkthrough showing a few different areas of how Kubernetes works along with deploying and using an Operator.
BottomLine: Great hands on for Operator development showing a few areas of Kubernetes pretty well
==
URL reference: https://medium.com/@subhamchand200/kubernetes-with-helm-kubernetes-for-absolute-beginners-772f4bb84aec
DateReviewed: 2024-09-05
Description: Kubernetes can be overwhelming to those who are new, despite it being a very popular and emerging app deployment option. The author argues that using Helm can bring down this barrier and make Kubernetes more approachable. We start with a quick background to what K8s is and a blurb about how it's managed and what it does. We then dive into a list of K8s features, like orchestration, self healing, discovery and so on - a list of 5 with a solid sentence each. On to Helm, which is positioned as a package manager like Yum or Apt for Linux distros. We get another 5 part list, where versioning, config/dependency management, charts and releases all make an appearence with our same one sentence summary. Next up is a pitch for using Helm with K8s, which is a 4 part list which boils down to simpler and easier overall. We have some prereqs, including basic knowledge of containers, a K8s cluster and a Helm install; but apparently we're going to help. Yes, we actuall go through a Helm install, and also a K8s cluster, but curiously we tackle Helm first and then K8s. Once we're here, we add a Helm reop and finally deploy a chart to verify the install. Weirdly, there seem to be CLI commands, but they aren't denoted as such, so I'm not sure how a beginner would follow this. We then run this on our K8s cluster, getting an Ingress app deployed. We now come to a spot where we get into some "advanced" Helm features, including rolling a chart of your own so you can deploy your own app. My take is while there are a few hiccups, this is a good piece overall. It feels like it was written in one environment though and translated over to medium, without doing the markup needed to have code blocks. Worth a read, but probably not the best intro.
BottomLine: Decent Kubernetes with Helm for beginners intro with some formatting challenges
==
URL reference: https://dev.to/prodevopsguytech/kubernetes-commands-for-devops-engineers-124o
DateReviewed: 2024-09-06
Description: After an extremely short background paragraph, this piece is a speed run through the core and many useful commands and concepts related to Kubernetes clusters. We start with a small key concepts section, and then dive into the beginner commands. This includes cluster info, namespace management, pod management, deployment management and service management. Each section presents 2-4 commands with an example. They do the same for intermediate and advanced commands, building up a solid stable of commands that can be used. To close, they do talk about a few best practices, but there are 5 short sentences devoted to it. Overall it's a good reference, but without a bit more context it might be hard for a beginner to leverage this.
BottomLine: Great reference to Kubernetes commands but lacking context for a beginnner
==
URL reference: https://www.sharepointeurope.com/decoding-azure-security-with-azure-file-share-mount-on-aks-workloads/
DateReviewed: 2024-09-07
Description: This piece starts with the claim that Azure security can be complex, and it is important to understand the fundamentals. We start with a crude diagram, and a story about sharing an Azure fileshare with an AKS cluster. Now they mention for various reasons what they couldn't use, they ended up settling on Workload identity. They include a decent diagram on how this flow works. We then are treated to a walkthrough of the steps they performed. We start with a bunch of enviroment variables, and then a CLI command to enable this kind of auth in AKS. There are a few more steps to get the basic auth all set up, then settimg up the perms so that the actual SMB share can be accessed. There is a bit more K8s stuff needed, which is an ID to access and finally a storage class to wrap the actual share (optional), and a persistent volume to surface the share in K8s. To actually use this, we now need a PV claim for the pod it should be used on and then to snag it. So, while conceptually this makes sense, it would need a few more diagrams and maybe a bit of video to actually make it comprehensible.
BottomLine: Walkthrough of mounting an Azure drive to Kubernetes with AKS
==
URL reference: https://dev2ops.hashnode.dev/security-in-terms-of-containerskubernetes
DateReviewed: 2024-09-07
Description: So, different cloud providers have various tools for K8s stuff, so our author proposes using a custom K8s client for each task. Small diagram, yay, but then a few pieces - I think he's building a security wrapper, but doesn't describe it much. There are 6 pieces, and it's all point form; so done quickly. Could be good, but isn't too substantial.
BottomLine: Bit too quick for a security piece.
==
URL reference: https://securityboulevard.com/2024/01/mastering-kubernetes-in-on-premises-environments/
DateReviewed: 2024-09-07
Description: Kubernetes is the cornerstone of cloud-native tech; we do a bit of a dive into private clouds, including a chart. They argue that on-prem K8s is not a variation of the public cloud version, but a specialized revision for the on-prem world. We then get to a list of benefits, which strangely seem very similar to the in-cloud versions. And now we actually dig in and talk about issues with the on-prem versions - think like no cloud vendor management, hardware management and networking complexity. Lastly, there are storage considerations to take into account. We do take a quick tour through the many tools to help with networking, storage and extensibility that might be a consideration in an on-prem deployment. They also contrast full Cloud service providers to spots that do Managed Kubernetes services, like Rancher, OpenSshift and vSphere. They also talk a bit about smaller companies that are providing solutions in this space. We're now taken on a tour of features these Managed K8s providers might provide, like streamlined installs/upgrads, security, multi-cluster support and general K8s support and expertise. We then walk through some high level approaches to K8s management, focused on security, like etcd encryption, hardening the API server, and good kubelet configuration practices. They also touch on TLS, along with proactively managing security vulns, adding admission controllers to enforce security policies, and perfroming security assessments. Overall, a good read. 
BottomLine: Decent read on various on-prem Kubernetes issues and approaches
==
URL reference: https://7wdata.be/devops/cloud-native-security-and-performance-two-sides-of-the-same-coin/
DateReviewed: 2024-09-08
Description: Our article poses the interesting question -- should you have a patch to a Prod Kubernetes system, how long should that take to roll out? They argue that microservices are ephemeral, but even being fleeting can be dangerous if the moments it is working are unpatched. A good DevOps process can release code weekly, daily or even hourly, which they argue reduces risk. They also link security to performance, in that both of them require similar approaches in monitoring and ability to turn things around. They further argue that good performance monitoring can alert to things like DoS attacks. They point out that traditionally, there was a multi-step process for rolling out patches, which might take up to a few weeks, while leaving systems open to potential attacks. They do point out that patches are risky because of unknown interactions, and that is why the testing and delays happen. We then come to a handwave, where "cloud native principles" solve all the issues, so use Kubernetes? My take is this starts out strong, but doesn't explain WHY the cloud native principles are so strong -- you can test on a subset, you can easily roll back if you hit an issue, etc. But the fact that I'm saying it and they didn't is the issue.
BottomLine: Interesting premise that doesn't follow through in the end - best to skip
==
URL reference: https://techcommunity.microsoft.com/t5/microsoft-defender-for-cloud/leveraging-azure-native-tooling-to-hunt-kubernetes-security/ba-p/4217705
DateReviewed: 2024-09-08
Description: This article is the intro to a way to figure out if our containers are different than we deployed them. They are looking for something called binary drift, where deployed containers are different then the images they were created from. They aim to build understanding of the security risks of binary drift, figure out how to detect drift, and finally prevent such drift from occuring in the first place. This is all happening on Azure and AKS, and they set out some base assumptions they have. They show how to configure Defender to look for drift, and also point out that by default, it is set to ignore drift in the rules. Overall an interesting topic.
BottomLine: Good intro as part of a series on Azure drift detection in Kubernetes
==
URL reference: https://itnext.io/choosing-the-perfect-kubernetes-workload-a-practical-guide-for-application-success-fe905c40788a
DateReviewed: 2024-09-08
Description: This article is about choosing an optimal Kubernetes workload - I don't know what that means exactly, but I guess we're going to find out! We start with a mind map, which is an interesting way to illustrate things. We then walk through a number of K8s concepts, like Deployments, StatefulSets and DaemonSets to name a few. Ah, what they mean is that you should use the K8s resource that matches the pattern of the app you are deploying. So, for instance, for a web application, they use Deployments. The explain why they think this is a good resource, along with an example walkthrough including a YAML file. They talk about a new to me resource, PodDisruptionBudget, which is a way to ensure a minimum number of pods during things like maintenence. They also go through a detailed example of dynamice scaling. I'm going to stop here, but they don't -- they go through several patterns, in lots of detail. Honestly, this is a hidden gem, and I'd for sure put this on the must read list.
BottomLine: Odd title but excellent article on various ways to run and control apps in Kubernetes - recommended
==
URL reference: https://cloud.google.com/blog/products/identity-security/create-a-powerful-kubernetes-security-duo-with-custom-org-policy-and-policy-controller/
DateReviewed: 2024-09-09
Description: This is an interesting control, from Google on their GKE Kubernetes line, to enhance what things can be allowed or restricted at a high level. They point out you can use Custom org policies to centralize controls and standardize them, creating guadrails. They talk about what they are able to do and how to craft them at a high level, and point out they can be org, folder or project in scope. They come with things like simulation and dryrun, to preview violations and identify runtime issues. They go through a number of things the policies can restrict or enforce, like making sure clusters have an identity or requiring logging. They then dig into Policy controller a bit, which is guardrails for policies. You can have it in dryrun, warn or enforcing mode, and can use it to ensure security and governance concerns aren't violated. They talk about policy bundles, which you can use to craft your policies and 80 templates to get started with in their library. They go through a number of scenarios you might use them. Finally, we get a discussion of when and how to use the two different systems. And we get a diagram -- basically Org policy is overall, and Policy controller is at the fleet or cluster level. Interesting high level walkthrough.
BottomLine: New tool aimed at Google Cloud Kubernetes for more layed approach to security and governance control
==
URL reference: https://rad.security/blog/security-features-in-kubernetes-latest-version-1.31
DateReviewed: 2024-09-09
Description: This article will take a look at new security improvements in the latest version of Kubernetes. The first one they dive into is around anonymous access -- by default, K8s can be very open, and an attack last year leveraged this default openness to launch workloads for cryptomining. The new mechanism only allows specific endpoints to serve anonymous requests, meaning even if your RBAC doesn't restrict it, it won't be processed if it isn't in the allow list. The next feature they talk about is SupplementalGroups, and what they can do. They point out this is now controlled at two levels -- OCI and K8s API, and this can create a gap that allow a container access that isn't intended by the cluster owner. This new feature adds an API field that specifies the exact levels and allows inspection, ensuring containers get the right permissions. Next up is enhancements around service accounts. As they are mostly used by apps, service accounts are often neglected or forgotten in the overall scheme of things. The new feature allows binding to the token info like where the access request came from originally, simplifying things like ensuring a match to the current requestor. Next up is improvements in the kube-proxy handling; we start with a bit of background on kube-proxy and move onto how it is handled. They talk about ipvs and iptables, and how iptables has some issues, and the intent is to replace it with nftables and provide a migration path. Next up is using field or label selectors for authorization decisions, basically making that path more flexible. There are a coupe file related ones -- one is a fix that makes read-only mounts truly read only, the other is split image, allowing the image/readable layer to be split from the container/writable layer where kubelet writes its temporary files -- the idea here to up performance on the write bits by seperating them more formally from the underlying non-changing bits. Rounding it out is AppArmor support, profiling support in kubectl debug and service CIDRs that have entered beta. Overall, a bevvy of features!
BottomLine: Good overview of new security related features in Kubernetes 1.31
==
URL reference: https://itnext.io/kubernetes-the-art-of-zero-downtime-deployments-fa92c8ec5646
DateReviewed: 2024-09-10
Description: Downtime is bad, but Kubernetes offers a way to do things with no downtime. You need to have a proper approach and strategy for this to work. We have a mindmap again, but targeted towards types of updates. We dive right in, starting with the built in rolling updates, where you specify the number of replicas and K8s does all the work. We take a sidebar where they explain how we target pods in a Deployment - namely, labels. Thus, the tagged or labelled pods are the ones to focus on. We move back to deployments, and talk a bit about rolling updates, with an example chat app. They dive into a bit of the settings here, but the important part is we have to specify we want one pod always available. We then run the rollout, and we can issue CLI commands to see the status and when the rollout completes. They explain what happens if a failure in the new version occurs, and how you can have an automatic rollback. We now move onto a more straightforwad deployment technique, which just stops the pods and creates new ones; this involves downtime, and they target this at the dev environment. They talk about some strategies, including graceful shutdown, to ensure as little impact to users as possible. They also touch on readiness probes, what they do and how they work. Now we move onto other deployment types, like blue/green and canaries. We start with a diagram for the Blue/Green, and then continue with a discussion of how this progresses. Then we pivot to Canary, also starting with a diagram. We also go through how a Canary deployment works. For both types, the new version is rolled out in the background, and after a criteria is met switched to. With B/G it is usually an internal test, while with Canary it's a small external one. They discuss some other deployment types, including Argo, hybrid and a few others, talking about the pros and cons of each. Overall, a great piece and very well rounded.
BottomLine: Great piece talking about minimizing downtime by using various Kubernetes rollout strategies
==
URL reference: https://cilium.io/blog/2024/08/14/hubble-for-network-security-and-observability-part-1/
DateReviewed: 2024-09-11
Description: Kubernetes is the defacto orchestrator for containers, but there is complexity in them there hills. So we are going to see how Hubble and Cilium can help simplify stuff. We start with a primer on what is Cilium, which they go through some of the features at a high level. Next is Hubble, which is the observability layer for Cilium, allowing you to see the network traffic Cilium is processing. Again, we get some high level features. They position it for network security, and argue it is strong because of native K8s integration, eBPF powered performance, deep visibility and API aware visibility and security, which they have a sentence about each of. They link to docs and intros, as well as labs and ways to use Cilium even if you don't want to replace your current CNI. We then get 5 real world testimonials, to help motivate us on our choice. An interesting piece.
BottomLine: Piece that argues using Cilium and Hubble for your Kubernetes network security needs in a pretty compelling way
==
URL reference: https://www.cncf.io/blog/2024/07/23/authentication-vs-authorization-understanding-the-difference/
DateReviewed: 2024-09-11
Description: There are two key concepts in allowing access to data and apps - authentication and authorization. This piece will try to break them apart. We start with Authentication, which they stylize as AuthN. Basically this is "who are you", with a bit of proof. Most commonly user/pass, can encompass things like MFA or biometrics. Next up is authorization, styled AuthZ. Here we know who you are, but we have to figure out what you should have access to. In K8s context, this is primarily through things like RBAC, but Attribute (ABAC) can also come into play. We then go through a bit of discussion about how they work together to do what they need to do. They talk about sequence (authN before authZ), and how it is critical that each is strong and that helps the other. They also talk again about what they each mean and do. They then take us through a real world example, talking about logins and then what we can do on a social media site -- we can change our profile, but not others, for instance. Finally, some pointers on choosing the "right" solution -- things to consider like scale and flexibility, best practices, and finally the possibility of outsourcing complexity. A good understandable walk through this topic.
BottomLine: Intro to the difference between Authentication and Authorization and their impact on security
==
URL reference: https://medium.com/@nbryleibanez/how-to-deploy-a-containerized-django-application-in-a-local-kubernetes-cluster-5f2a0bbf23a0
DateReviewed: 2024-09-12
Description: First, we start with a bit of a backgrounder on microservices, and how Docker and Kubernetes play a role, and they explain how resilience, scalability and ease of deployment are all made better. We then start with a ref to K8s and Docker documentation, and we do a quick primer for both Docker and K8s. Next up we go through a list of pre-reqs to get going with the tutorial. They then dig in, by explaining we'll deploy a simple Django project to get the idea of what is going on. After creating a directory for our dev, we then fire up a virtual Python env to allow us to build up our various libraries and dependencies. We then use PIP to install Django and Uvicorn, and finally create a Django project. We then grab our current dependencies and create a requirements.txt file with them. We then do some simple configs, and they show us the full settings.py as a screenshot. We also have to tweak urls.py, to reference local files. Finally, we set up the static files with a Python CLI command. They then run uvicorn to fire up a web server and show our Django app is working. We now pivot to creating an image, so they show us the Dockerfile we will need to build the initial container, and walk through it line by line. They then execute the CLI command that will create the Docker image from the CLI, and explain it. They then show us how to check on the image in Docker, and then run the container. They show us some ways to get info from Docker, including logs and container status, and explain howo we can access the new app. Once we confirm it works, they give us the CLI to spin down the container. We then run through putting the image into a repo, namely Docker Hub. We then run through how to use K8s to snag the image and run it as a pod, and how to verify it is running. To tie it up, they show how to spin down the K8s resources. It's a decent walktrhough for a Python person new to containers.
BottomLine: Solid tutorial on getting a simple Django app running as a microservive on Kubernetes
==
